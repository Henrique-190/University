{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import holidays\n",
    "from collections import Counter\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,plot_confusion_matrix, accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leitura\n",
    "incidentes = pd.read_csv('../input/training_data.csv')\n",
    "teste = pd.read_csv('../input/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remoção de colunas desnecessárias\n",
    "incidentes=incidentes.drop(['city_name'],axis=1)\n",
    "incidentes=incidentes.drop(['avg_precipitation'],axis=1)\n",
    "teste=teste.drop(['city_name'],axis=1)\n",
    "teste=teste.drop(['avg_precipitation'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformação para numéricas\n",
    "incidentes[\"avg_rain\"] = incidentes['avg_rain'].replace({'Sem Chuva' : 0, 'chuva fraca' : 1, 'chuva moderada' : 2, 'chuva forte' : 3}).astype(int)\n",
    "incidentes[\"magnitude_of_delay\"] = incidentes['magnitude_of_delay'].replace({'UNDEFINED' : 0, 'MODERATE' : 1, 'MAJOR' : 2}).astype(int)\n",
    "incidentes['luminosity'] = incidentes['luminosity'].replace(['DARK','LOW_LIGHT','LIGHT'],[0,1,2]).astype(int)\n",
    "incidentes['record_date'] = pd.to_datetime(incidentes['record_date'])\n",
    "incidentes[\"incidents\"] = incidentes['incidents'].replace({'None' : 0, 'Low' : 1, 'Medium' : 2, 'High' : 3, 'Very_High' : 4}).astype(int)\n",
    "\n",
    "teste[\"avg_rain\"] = teste['avg_rain'].replace({'Sem Chuva' : 0, 'chuva fraca' : 1, 'chuva moderada' : 2, 'chuva forte' : 3}).astype(int)\n",
    "teste[\"magnitude_of_delay\"] = teste['magnitude_of_delay'].replace({'UNDEFINED' : 0, 'MODERATE' : 1, 'MAJOR' : 2}).astype(int)\n",
    "teste['luminosity'] = teste['luminosity'].replace(['DARK','LOW_LIGHT','LIGHT'],[0,1,2]).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cenário 1.2 - Feature Engeneering com método diferente"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Método diferente para tratar as estradas afetadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MÉTODO 2\n",
    "# create the two new columns\n",
    "incidentes[\"National\"] = 0\n",
    "incidentes[\"Regional\"] = 0\n",
    "\n",
    "def treat_affected_roads_types(df):\n",
    "    # Check if the value in the \"affected_roads\" column is null, empty, or equal to \",\"\n",
    "    mask = df[\"affected_roads\"].isnull() | df[\"affected_roads\"].eq(\"\") | df[\"affected_roads\"].eq(\",\")\n",
    "    df.loc[mask, \"National\"] = 0\n",
    "    df.loc[mask, \"Regional\"] = 0\n",
    "    \n",
    "    # For the remaining rows, split the string in the \"affected_roads\" column by comma and count the occurances of each road type\n",
    "    for index, row in df[~mask].iterrows():\n",
    "        # Create a Counter object to store the counts of each road type\n",
    "        road_counts = Counter({\"N\": 0, \"R\": 0})\n",
    "        \n",
    "        # Split the string and update the counts in the Counter object\n",
    "        roads = row[\"affected_roads\"].split(\",\")\n",
    "        for road in roads:\n",
    "            # Use a regular expression to extract the road type\n",
    "            road_type = re.search(\"^[NR]\\d+\", road)\n",
    "            if road_type:\n",
    "                road_type = road_type.group()[0]\n",
    "                road_counts[road_type] += 1\n",
    "        \n",
    "        # Set the values in the new columns\n",
    "        df.loc[index, \"National\"] = road_counts[\"N\"]\n",
    "        df.loc[index, \"Regional\"] = road_counts[\"R\"]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidentes = treat_affected_roads_types(incidentes)\n",
    "teste = treat_affected_roads_types(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover a coluna tratada\n",
    "incidentes=incidentes.drop(['affected_roads'],axis=1)\n",
    "teste=teste.drop(['affected_roads'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tratar o record_time\n",
    "# treino\n",
    "incidentes['record_date'] = pd.to_datetime(incidentes['record_date'])\n",
    "incidentes['day_of_month'] = incidentes['record_date'].dt.day\n",
    "incidentes['week_day'] = incidentes['record_date'].dt.weekday\n",
    "incidentes['month'] = incidentes['record_date'].dt.month\n",
    "incidentes['year'] = incidentes['record_date'].dt.year\n",
    "incidentes['hour'] = incidentes['record_date'].dt.hour\n",
    "incidentes['minute'] = incidentes['record_date'].dt.minute\n",
    "incidentes['day_of_year'] = incidentes['record_date'].dt.dayofyear\n",
    "\n",
    "# teste\n",
    "teste['record_date'] = pd.to_datetime(teste['record_date'])\n",
    "teste['day_of_month'] = teste['record_date'].dt.day\n",
    "teste['week_day'] = teste['record_date'].dt.weekday\n",
    "teste['month'] = teste['record_date'].dt.month\n",
    "teste['year'] = teste['record_date'].dt.year\n",
    "teste['hour'] = teste['record_date'].dt.hour\n",
    "teste['minute'] = teste['record_date'].dt.minute\n",
    "teste['day_of_year'] = teste['record_date'].dt.dayofyear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover essa coluna\n",
    "incidentes.drop('minute', axis=1, inplace=True)\n",
    "incidentes.drop('year', axis=1, inplace=True)\n",
    "teste.drop('minute', axis=1, inplace=True)\n",
    "teste.drop('year', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Vamos extrair algumas features que podem ter interesse:\n",
    "    * Estação do Ano;\n",
    "    * Fim de semana;\n",
    "    * Feriado;\n",
    "* A ideia é depois relacionar com as métricas e verificar se o modelo melhorou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obter estação do ano para cada dia\n",
    "def get_season(df):\n",
    "    seasons = []\n",
    "    for index, row in df.iterrows():\n",
    "        # Access the data in each column by column name\n",
    "        month = row['month']\n",
    "        day = row['day_of_month']\n",
    "    \n",
    "        # Determine the season based on the month and day of the month\n",
    "        if month in [3, 4, 5]:\n",
    "            # For March, April, and May, use the day to determine the season\n",
    "            if day < 21:\n",
    "                season = 0\n",
    "            else:\n",
    "                season = 1\n",
    "        elif month in [6, 7, 8]:\n",
    "            season = 1\n",
    "        elif month in [9, 10, 11]:\n",
    "            # For September, October, and November, use the day to determine the season\n",
    "            if day < 21:\n",
    "                season = 2\n",
    "            else:\n",
    "                season = 3\n",
    "        else:\n",
    "            season = 3\n",
    "        seasons.append(season)\n",
    "    return seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidentes['season'] = get_season(incidentes)\n",
    "teste['season'] = get_season(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determina se é ou não um dia de férias\n",
    "def is_holidays(df):\n",
    "    pt_holidays = holidays.CountryHoliday(\"PT\")\n",
    "    df[\"is_holiday\"] = 0\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        date_field = row[\"record_date\"]\n",
    "        if date_field in pt_holidays:\n",
    "            df.at[i, \"is_holiday\"] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidentes = is_holidays(incidentes)\n",
    "teste = is_holidays(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determina se é fim de semana ou não\n",
    "def is_weekend(df):\n",
    "    df[\"is_weekend\"] = 0\n",
    "    for i, row in df.iterrows():\n",
    "        date_field = row[\"week_day\"]\n",
    "        if date_field in [0, 4]:\n",
    "            df[\"is_weekend\"] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidentes = is_weekend(incidentes)\n",
    "teste = is_weekend(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podemos remover a coluna\n",
    "incidentes.drop('record_date', axis=1, inplace=True)\n",
    "# podemos remover a coluna\n",
    "teste.drop('record_date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magnitude_of_delay</th>\n",
       "      <th>delay_in_seconds</th>\n",
       "      <th>luminosity</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>avg_atm_pressure</th>\n",
       "      <th>avg_humidity</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>avg_rain</th>\n",
       "      <th>incidents</th>\n",
       "      <th>National</th>\n",
       "      <th>Regional</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>week_day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>season</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>359</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2297</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>272</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   magnitude_of_delay  delay_in_seconds  luminosity  avg_temperature  \\\n",
       "0                   0                 0           0             12.0   \n",
       "1                   0               385           0             12.0   \n",
       "2                   0                69           2             14.0   \n",
       "3                   2              2297           2             15.0   \n",
       "4                   0                 0           2             27.0   \n",
       "\n",
       "   avg_atm_pressure  avg_humidity  avg_wind_speed  avg_rain  incidents  \\\n",
       "0            1013.0          70.0             1.0         0          0   \n",
       "1            1007.0          91.0             1.0         0          0   \n",
       "2            1025.0          64.0             0.0         0          1   \n",
       "3            1028.0          75.0             1.0         0          4   \n",
       "4            1020.0          52.0             1.0         0          3   \n",
       "\n",
       "   National  Regional  day_of_month  week_day  month  hour  day_of_year  \\\n",
       "0         0         0            15         0      3    23           74   \n",
       "1         1         0            25         5     12    18          359   \n",
       "2         0         0            12         4      3    15           71   \n",
       "3        10         1            29         2      9     9          272   \n",
       "4         5         0            13         6      6    11          164   \n",
       "\n",
       "   season  is_holiday  is_weekend  \n",
       "0       0           0           1  \n",
       "1       3           1           1  \n",
       "2       0           0           1  \n",
       "3       3           0           1  \n",
       "4       1           0           1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incidentes.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "* Vamos verificar se há alterações nas métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divisão do target\n",
    "x = incidentes.drop(['incidents'], axis=1)\n",
    "y = incidentes['incidents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que constrói os modelos, apresentando as métricas\n",
    "def train_and_predict(X, y, teste):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    models = [RandomForestClassifier(n_estimators=100, max_features=\"auto\", random_state=42),\n",
    "             LGBMClassifier(boosting_type='gbdt', learning_rate=0.1, n_estimators=100, random_state=42),\n",
    "             GradientBoostingClassifier(learning_rate=0.1, n_estimators=100, random_state=42),\n",
    "             DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=20, random_state=42),\n",
    "             ExtraTreesClassifier(criterion='gini', max_depth=20, random_state=42),\n",
    "             KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto')]\n",
    "             \n",
    "    reports=[]\n",
    "    acc = []\n",
    "    pred = []\n",
    "    names = ['RF','LGB','GB','DT','ET','KN']\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        reports.append(report)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        acc.append(accuracy)\n",
    "        test_predictions = model.predict(teste)\n",
    "        pred.append(test_predictions)\n",
    "\n",
    "    i = 0   \n",
    "    #Print the reports side by side\n",
    "    for i, report in enumerate(reports):\n",
    "        print(\"Model {} {}:\\n{}\".format(i + 1, names[i], report))\n",
    "        print(\"Accuracy: {:.5f}\".format(acc[i]))\n",
    "        print(\"=\" * 50)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/purp/anaconda3/envs/dataset_COMPETICAO/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7ff76ea87700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/purp/anaconda3/envs/dataset_COMPETICAO/lib/python3.9/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/purp/anaconda3/envs/dataset_COMPETICAO/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/purp/anaconda3/envs/dataset_COMPETICAO/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/purp/anaconda3/envs/dataset_COMPETICAO/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7ff76ea87700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/purp/anaconda3/envs/dataset_COMPETICAO/lib/python3.9/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/purp/anaconda3/envs/dataset_COMPETICAO/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/purp/anaconda3/envs/dataset_COMPETICAO/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/purp/anaconda3/envs/dataset_COMPETICAO/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       517\n",
      "           1       0.87      0.91      0.89       189\n",
      "           2       0.85      0.83      0.84       144\n",
      "           3       0.93      0.87      0.90       265\n",
      "           4       0.89      0.95      0.92       135\n",
      "\n",
      "    accuracy                           0.93      1250\n",
      "   macro avg       0.90      0.91      0.91      1250\n",
      "weighted avg       0.93      0.93      0.93      1250\n",
      "\n",
      "Accuracy: 0.92960\n",
      "==================================================\n",
      "Model 2 LGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       517\n",
      "           1       0.90      0.93      0.91       189\n",
      "           2       0.85      0.83      0.84       144\n",
      "           3       0.92      0.89      0.91       265\n",
      "           4       0.90      0.95      0.92       135\n",
      "\n",
      "    accuracy                           0.94      1250\n",
      "   macro avg       0.91      0.92      0.91      1250\n",
      "weighted avg       0.94      0.94      0.94      1250\n",
      "\n",
      "Accuracy: 0.93760\n",
      "==================================================\n",
      "Model 3 GB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       517\n",
      "           1       0.84      0.89      0.86       189\n",
      "           2       0.79      0.72      0.75       144\n",
      "           3       0.89      0.85      0.87       265\n",
      "           4       0.89      0.92      0.91       135\n",
      "\n",
      "    accuracy                           0.91      1250\n",
      "   macro avg       0.88      0.88      0.88      1250\n",
      "weighted avg       0.91      0.91      0.91      1250\n",
      "\n",
      "Accuracy: 0.90960\n",
      "==================================================\n",
      "Model 4 DT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       517\n",
      "           1       0.88      0.91      0.89       189\n",
      "           2       0.83      0.81      0.82       144\n",
      "           3       0.89      0.89      0.89       265\n",
      "           4       0.91      0.87      0.89       135\n",
      "\n",
      "    accuracy                           0.92      1250\n",
      "   macro avg       0.90      0.89      0.90      1250\n",
      "weighted avg       0.92      0.92      0.92      1250\n",
      "\n",
      "Accuracy: 0.92240\n",
      "==================================================\n",
      "Model 5 ET:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       517\n",
      "           1       0.84      0.83      0.83       189\n",
      "           2       0.82      0.78      0.80       144\n",
      "           3       0.89      0.87      0.88       265\n",
      "           4       0.89      0.92      0.90       135\n",
      "\n",
      "    accuracy                           0.91      1250\n",
      "   macro avg       0.88      0.88      0.88      1250\n",
      "weighted avg       0.91      0.91      0.91      1250\n",
      "\n",
      "Accuracy: 0.90640\n",
      "==================================================\n",
      "Model 6 KN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       517\n",
      "           1       0.74      0.74      0.74       189\n",
      "           2       0.72      0.66      0.69       144\n",
      "           3       0.78      0.77      0.78       265\n",
      "           4       0.78      0.81      0.79       135\n",
      "\n",
      "    accuracy                           0.83      1250\n",
      "   macro avg       0.79      0.79      0.79      1250\n",
      "weighted avg       0.83      0.83      0.83      1250\n",
      "\n",
      "Accuracy: 0.83360\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "preds = train_and_predict(x,y,teste)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação\n",
    "\n",
    "| **Modelo**                          | **Antes** | **Depois** | **Obs**      | **Depois (M2)**|\n",
    "|-------------------------------------|-----------|------------|--------------|----------------|\n",
    "| **K Neighbors Classifier**          | 0.8312    | 0.83120    | **Manteve**  |       0.83360  |\n",
    "| **Extra Trees Classifier**          | 0.8968    | 0.89760    | **Melhorou** |         0.90640|\n",
    "| **Gradient Boosting Classifier**    | 0.8984    | 0.90000    | **Melhorou** |      0.90960   |\n",
    "| **Decision Tree Classifier**        | 0.9080    | 0.90640    | Piorou       |         0.92240|\n",
    "| **Random Forest Classifier**        | 0.9168    | 0.92480    | **Melhorou** |      0.92960   |\n",
    "| **Light Gradient Boosting Machine** | 0.9232    | 0.92240    | Piorou       |   0.93760      |\n",
    "\n",
    "Todos melhoraram com este método, fica este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidentes.to_csv(\"../input/train_data_cleaned.csv\")\n",
    "teste.to_csv(\"../input/test_data_cleaned.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os modelos melhoraram com este tratamento.\n",
    "Neste momento já temos features com relevância para os nossos modelos, vamos, então, realizar um tratamento específico, para os top-3.\n",
    "Seguir para o notebook 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset_COMPETICAO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af40022f6b24da7d0ec2d2ff3772b63b87a9d2e288a5206d322010ec73befb1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
